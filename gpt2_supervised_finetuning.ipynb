{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb10b53-a398-43f1-b0d3-5c740226ba03",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Downloading mlflow-3.9.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting mlflow-skinny==3.9.0 (from mlflow)\n",
      "  Downloading mlflow_skinny-3.9.0-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting mlflow-tracing==3.9.0 (from mlflow)\n",
      "  Downloading mlflow_tracing-3.9.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting Flask-CORS<7 (from mlflow)\n",
      "  Downloading flask_cors-6.0.2-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting Flask<4 (from mlflow)\n",
      "  Downloading flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Downloading alembic-1.18.3-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting cryptography<47,>=43.0.0 (from mlflow)\n",
      "  Downloading cryptography-46.0.4-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from mlflow) (7.1.0)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting gunicorn<24 (from mlflow)\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting huey<3,>=2.5.4 (from mlflow)\n",
      "  Downloading huey-2.6.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: matplotlib<4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from mlflow) (3.8.2)\n",
      "Requirement already satisfied: numpy<3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from mlflow) (1.26.4)\n",
      "Requirement already satisfied: pandas<3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from mlflow) (2.1.4)\n",
      "Collecting pyarrow<23,>=4.0.0 (from mlflow)\n",
      "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: scikit-learn<2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from mlflow) (1.3.2)\n",
      "Requirement already satisfied: scipy<2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from mlflow) (1.11.4)\n",
      "Collecting skops<1 (from mlflow)\n",
      "  Downloading skops-0.13.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting sqlalchemy<3,>=1.4.0 (from mlflow)\n",
      "  Downloading sqlalchemy-2.0.46-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting cachetools<7,>=5.0.0 (from mlflow-skinny==3.9.0->mlflow)\n",
      "  Downloading cachetools-6.2.6-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from mlflow-skinny==3.9.0->mlflow) (8.3.1)\n",
      "Collecting cloudpickle<4 (from mlflow-skinny==3.9.0->mlflow)\n",
      "  Downloading cloudpickle-3.1.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.9.0->mlflow)\n",
      "  Downloading databricks_sdk-0.85.0-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: fastapi<1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from mlflow-skinny==3.9.0->mlflow) (0.128.1)\n",
      "Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==3.9.0->mlflow)\n",
      "  Downloading gitpython-3.1.46-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting importlib_metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==3.9.0->mlflow)\n",
      "  Downloading importlib_metadata-8.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.9.0->mlflow)\n",
      "  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.9.0->mlflow)\n",
      "  Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.9.0->mlflow)\n",
      "  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: packaging<26 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from mlflow-skinny==3.9.0->mlflow) (25.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from mlflow-skinny==3.9.0->mlflow) (6.33.5)\n",
      "Requirement already satisfied: pydantic<3,>=2.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from mlflow-skinny==3.9.0->mlflow) (2.12.5)\n",
      "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from mlflow-skinny==3.9.0->mlflow) (1.2.1)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from mlflow-skinny==3.9.0->mlflow) (6.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from mlflow-skinny==3.9.0->mlflow) (2.32.5)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==3.9.0->mlflow)\n",
      "  Downloading sqlparse-0.5.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from mlflow-skinny==3.9.0->mlflow) (4.15.0)\n",
      "Requirement already satisfied: uvicorn<1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from mlflow-skinny==3.9.0->mlflow) (0.40.0)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from cryptography<47,>=43.0.0->mlflow) (2.0.0)\n",
      "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow)\n",
      "  Downloading google_auth-2.48.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
      "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from fastapi<1->mlflow-skinny==3.9.0->mlflow) (0.50.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from fastapi<1->mlflow-skinny==3.9.0->mlflow) (0.0.4)\n",
      "Collecting blinker>=1.9.0 (from Flask<4->mlflow)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting itsdangerous>=2.2.0 (from Flask<4->mlflow)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from Flask<4->mlflow) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from Flask<4->mlflow) (3.0.3)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from Flask<4->mlflow) (3.1.5)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==3.9.0->mlflow)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.9.0->mlflow)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Collecting zipp>=3.20 (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.9.0->mlflow)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib<4->mlflow) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib<4->mlflow) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib<4->mlflow) (3.3.2)\n",
      "Collecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.9.0->mlflow)\n",
      "  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas<3->mlflow) (2025.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.9.0->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.9.0->mlflow) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.9.0->mlflow) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.9.0->mlflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.9.0->mlflow) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.9.0->mlflow) (2026.1.4)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow)\n",
      "  Downloading pyasn1-0.6.2-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from scikit-learn<2->mlflow) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
      "Collecting prettytable>=3.9 (from skops<1->mlflow)\n",
      "  Downloading prettytable-3.17.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting greenlet>=1 (from sqlalchemy<3,>=1.4.0->mlflow)\n",
      "  Downloading greenlet-3.3.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.9.0->mlflow) (4.12.1)\n",
      "Requirement already satisfied: h11>=0.8 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from uvicorn<1->mlflow-skinny==3.9.0->mlflow) (0.16.0)\n",
      "Requirement already satisfied: pycparser in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography<47,>=43.0.0->mlflow) (3.0)\n",
      "Requirement already satisfied: wcwidth in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from prettytable>=3.9->skops<1->mlflow) (0.5.3)\n",
      "Downloading mlflow-3.9.0-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_skinny-3.9.0-py3-none-any.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_tracing-3.9.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.18.3-py3-none-any.whl (262 kB)\n",
      "Downloading cachetools-6.2.6-py3-none-any.whl (11 kB)\n",
      "Downloading cloudpickle-3.1.2-py3-none-any.whl (22 kB)\n",
      "Downloading cryptography-46.0.4-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading databricks_sdk-0.85.0-py3-none-any.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flask-3.1.2-py3-none-any.whl (103 kB)\n",
      "Downloading flask_cors-6.0.2-py3-none-any.whl (13 kB)\n",
      "Downloading gitpython-3.1.46-py3-none-any.whl (208 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading google_auth-2.48.0-py3-none-any.whl (236 kB)\n",
      "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Downloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
      "Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "Downloading huey-2.6.0-py3-none-any.whl (76 kB)\n",
      "Downloading importlib_metadata-8.7.1-py3-none-any.whl (27 kB)\n",
      "Downloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n",
      "Downloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n",
      "Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n",
      "Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading skops-0.13.0-py3-none-any.whl (131 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading sqlalchemy-2.0.46-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sqlparse-0.5.5-py3-none-any.whl (46 kB)\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading greenlet-3.3.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (609 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m609.9/609.9 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading prettytable-3.17.0-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.2-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: huey, zipp, sqlparse, smmap, pyasn1, pyarrow, prettytable, opentelemetry-proto, Mako, itsdangerous, gunicorn, greenlet, graphql-core, cloudpickle, cachetools, blinker, sqlalchemy, rsa, pyasn1-modules, importlib_metadata, graphql-relay, gitdb, Flask, cryptography, skops, opentelemetry-api, graphene, google-auth, gitpython, Flask-CORS, alembic, opentelemetry-semantic-conventions, databricks-sdk, opentelemetry-sdk, mlflow-tracing, mlflow-skinny, mlflow\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/37\u001b[0m [mlflow]36/37\u001b[0m [mlflow]skinny]]dk]onventions]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Flask-3.1.2 Flask-CORS-6.0.2 Mako-1.3.10 alembic-1.18.3 blinker-1.9.0 cachetools-6.2.6 cloudpickle-3.1.2 cryptography-46.0.4 databricks-sdk-0.85.0 gitdb-4.0.12 gitpython-3.1.46 google-auth-2.48.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 greenlet-3.3.1 gunicorn-23.0.0 huey-2.6.0 importlib_metadata-8.7.1 itsdangerous-2.2.0 mlflow-3.9.0 mlflow-skinny-3.9.0 mlflow-tracing-3.9.0 opentelemetry-api-1.39.1 opentelemetry-proto-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 prettytable-3.17.0 pyarrow-22.0.0 pyasn1-0.6.2 pyasn1-modules-0.4.2 rsa-4.9.1 skops-0.13.0 smmap-5.0.2 sqlalchemy-2.0.46 sqlparse-0.5.5 zipp-3.23.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m26.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce3e4a8c-997a-4ec1-8046-87258640ee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "\n",
    "import os, sys\n",
    "# sys.path += [\"/teamspace/studios/this_studio\"]\n",
    "\n",
    "import torch\n",
    "import random\n",
    "from torch import nn\n",
    "\n",
    "from typing import Iterator, Tuple\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gpt2tiny.tokenizer import Tokenizer\n",
    "import glob\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "\n",
    "from gpt2tiny.model import GPT2, GPTConfig\n",
    "# from dataset import PreTokDataset\n",
    "from gpt2tiny.dataset import SFTDataset, collator \n",
    "from gpt2tiny.trainer import TrainingConfig, SFTGPT2Module\n",
    "import torch.distributed as dist\n",
    "from typing import Iterator, Tuple\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "BASE_DIR = \"/teamspace/studios/this_studio/gpt2tiny\"\n",
    "DATA_CACHE_DIR = Path(BASE_DIR) / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41cf5eae-df99-4178-87f8-64ef1aa78f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/mlflow/tracking/_tracking_service/utils.py:178: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n",
      "  return FileStore(store_uri, store_uri)\n"
     ]
    }
   ],
   "source": [
    "mlf_logger = MLFlowLogger(\n",
    "    experiment_name=\"test\",\n",
    "    tracking_uri=f\"{BASE_DIR}/mlruns\",  # Colab-local (ephemeral) filesystem\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8c32dba-8666-4fab-809a-41a0240b1e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3da73050-1136-4207-8f7b-290d53df1db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GPTConfig(flash=True, vocab_size=8192, dropout=0.1)#, block_size=64)#, load_loss_coef=0.5)#,n_layer=1, n_head=2, n_embed=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d509617-661c-4e57-adb5-e584b51b619e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTConfig(block_size=512, vocab_size=8192, n_layer=8, n_head=8, n_embed=512, n_expert=2, k=1, dropout=0.1, bias=False, use_rotary=False, flash=True, noisy_gating=True, capacity_factor=10, load_loss_coef=0.01)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9348418-3833-4915-b191-b5087b6a9b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config = TrainingConfig(\n",
    "    batch_size=32,\n",
    "    num_workers=4,\n",
    "    max_iters=1000,\n",
    "    gradient_accumulation_steps=8,\n",
    "    eval_interval=10,\n",
    "    log_interval=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9a375f4-a7e4-4af5-bfe7-ac111c0f089f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingConfig(learning_rate=0.0006, max_iters=1000, weight_decay=0.1, beta1=0.9, beta2=0.95, grad_clip=1.0, decay_lr=True, warmup_iters=1000, lr_decay_iters=30000, min_lr=6e-05, eval_interval=10, log_interval=1, eval_iters=200, gradient_accumulation_steps=8, batch_size=32, num_workers=4, device='cuda', dtype='bfloat16', compile=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "061b9c5e-05d5-442d-8f19-370efac187ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(f\"{BASE_DIR}/data/tok8192.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8571c78-8053-4aa7-994b-ea7faf072024",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    SFTDataset(\n",
    "        split=\"train\",\n",
    "        data_dir=[DATA_CACHE_DIR / \"MetaMathQA\"],# DATA_CACHE_DIR / \"TinyStories_all_data\"],\n",
    "        weights=\"Balanced\",\n",
    "    ),\n",
    "    collate_fn=lambda batch: collator(batch, 0),\n",
    "    batch_size=trainer_config.batch_size,\n",
    "    num_workers=trainer_config.num_workers,\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    SFTDataset(\n",
    "        split=\"validation\",\n",
    "        data_dir=[DATA_CACHE_DIR / \"MetaMathQA\"],# DATA_CACHE_DIR / \"TinyStories_all_data\"],\n",
    "        weights=\"Balanced\",\n",
    "    ),\n",
    "    collate_fn=lambda batch: collator(batch, 0),\n",
    "    batch_size=trainer_config.batch_size,\n",
    "    num_workers=trainer_config.num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ff23967-20db-4395-ad41-1920e89bbd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = SFTGPT2Module.load_from_checkpoint(\"scratch/best-step=9775-val_loss=0.4077.ckpt\", weights_only=False, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63c8993b-341f-4b94-845c-cdb83af8955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",     # must match the name you log (self.log(\"val_loss\", ...))\n",
    "    mode=\"min\",\n",
    "    save_top_k=1,           # keep only the best\n",
    "    dirpath=f\"{BASE_DIR}/mlruns/{mlf_logger.experiment_id}/{mlf_logger.run_id}/artifacts/\",\n",
    "    filename=\"best-{step}-{val_loss:.4f}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42a0f772-a460-4562-b426-a839e6586617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,             # number of GPUs\n",
    "    precision=\"16-mixed\",  # optional, T4 benefits from AMP    \n",
    "    max_steps=trainer_config.max_iters,        # total training steps (defines run length)\n",
    "    val_check_interval=trainer_config.eval_interval,  # run validation every 2k training steps\n",
    "    limit_val_batches=200,   # cap validation to 200 batches per val loop\n",
    "    logger=mlf_logger,\n",
    "    callbacks=[checkpoint_cb],\n",
    "    log_every_n_steps=trainer_config.log_interval,\n",
    "    accumulate_grad_batches=trainer_config.gradient_accumulation_steps,\n",
    "    gradient_clip_val=trainer_config.grad_clip,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d26cd7f-ee73-40b4-b1ca-222dbff7bb59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:242: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━┳━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>┃\n",
       "┡━━━╇━━━━━━━╇━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ model │ GPT2 │ 29.6 M │ train │     0 │\n",
       "└───┴───────┴──────┴────────┴───────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━┳━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━╇━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ model │ GPT2 │ 29.6 M │ train │     0 │\n",
       "└───┴───────┴──────┴────────┴───────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 29.6 M                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 29.6 M                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 118                                                                        \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 112                                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 29.6 M                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 29.6 M                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 118                                                                        \n",
       "\u001b[1mModules in train mode\u001b[0m: 112                                                                                         \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ddb5c607fa04bba9e57a7225a9c858d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(module, train_dataloader, eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee9d5d4-a183-4070-a652-8b4413fb28ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24ed13fd-673c-4003-8383-6178e138e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2Module.load_from_checkpoint(\n",
    "    \"./mlruns/833148605187015421/964cb2ae845841cf90237bc1826cd54e/artifacts/best-step=4550-val_loss=1.4789.ckpt\",\n",
    "    config=config,\n",
    "    tokenizer=tokenizer,\n",
    "    gen_every_n_epochs=500,\n",
    "    prompts=[\"A dragon in a cave\", \"1+1 is\", \"The CMB is the\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "816f7617-5c0f-4ba2-acf6-b4036e2e781f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$(x+1)^2= The area of one square is calculated by multiplying its length by itself to $8\\times 10\\times x$.\n",
      "Since there are two legs, the perimeter of one leg must be $84/2=24$ cm.\n",
      "Therefore\n"
     ]
    }
   ],
   "source": [
    "prompt = \"There once was a man\"\n",
    "# prompt = \"A dragon in a cave\"\n",
    "# prompt = \"I like video games\"\n",
    "# prompt = \"2 + 2 is\"\n",
    "prompt = \"$(x+1)^2=\"\n",
    "raw_model = model.model\n",
    "_ = raw_model.eval()\n",
    "output = raw_model.generate(prompt, 55, top_k=10, top_p=None, tokenizer=tokenizer, temperature=1.5)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0c80570-c444-43c2-a7ee-4b3c576fc44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"There once was a girl named lily\"\n",
    "# prompt = \"A dragon in a cave\"\n",
    "# prompt = \"What is going on?\"\n",
    "# prompt = \"2 + 2 is\"\n",
    "prompt = \"$(x+1)^2=\"\n",
    "idx = tokenizer.encode(prompt, bos=True, eos=True)\n",
    "idx = torch.tensor(idx, dtype=torch.long).unsqueeze(0)\n",
    "device = next(raw_model.parameters()).device\n",
    "idx = idx.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21a47bac-34d3-4c57-beda-d39045498234",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T = idx.shape\n",
    "\n",
    "x = raw_model.transformer.wte(idx)\n",
    "\n",
    "pos_emb = raw_model.transformer.wpe(\n",
    "    torch.arange(T, device = idx.device, dtype=torch.long)\n",
    ")\n",
    "\n",
    "x = x + pos_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7182b77-ed21-4501-a2c7-f66df03e4fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "moe_data = []\n",
    "for bl in raw_model.transformer.h:\n",
    "    x = x + bl.attn(bl.ln_1(x))\n",
    "    \n",
    "    x_moe = bl.moe(bl.ln_2(x))\n",
    "\n",
    "    x = x + x_moe.y\n",
    "    moe_data.append(x_moe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a878749-5295-4a8d-a1b9-e2de58289c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.4918, 0.5082], device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor([0.5232, 0.4768], device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor([0.5178, 0.4822], device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor([0.5096, 0.4904], device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor([0.5084, 0.4916], device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor([0.6319, 0.3681], device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor([0.5076, 0.4924], device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor([0.5725, 0.4275], device='cuda:0', grad_fn=<DivBackward0>)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d.importance for d in moe_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "272f6359-79f8-411a-a578-4fa7694f3350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.4910, 0.5090], device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor([0.5436, 0.4564], device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor([0.5078, 0.4922], device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor([0.4938, 0.5062], device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor([0.5289, 0.4711], device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor([0.4715, 0.5285], device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor([0.4841, 0.5159], device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor([0.5791, 0.4209], device='cuda:0', grad_fn=<DivBackward0>)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d.importance for d in moe_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa11214e-ab88-48c5-bbf0-cf18c053dba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.3290, 0.6710], grad_fn=<DivBackward0>),\n",
       " tensor([0.3958, 0.6042], grad_fn=<DivBackward0>),\n",
       " tensor([0.4671, 0.5329], grad_fn=<DivBackward0>),\n",
       " tensor([0.3412, 0.6588], grad_fn=<DivBackward0>),\n",
       " tensor([0.4800, 0.5200], grad_fn=<DivBackward0>),\n",
       " tensor([0.5341, 0.4659], grad_fn=<DivBackward0>),\n",
       " tensor([0.7485, 0.2515], grad_fn=<DivBackward0>),\n",
       " tensor([0.2666, 0.7334], grad_fn=<DivBackward0>)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d.importance for d in moe_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca69b75f-6668-48d3-a260-ab8ab0875229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.3527, 0.6473], grad_fn=<DivBackward0>),\n",
       " tensor([0.4996, 0.5004], grad_fn=<DivBackward0>),\n",
       " tensor([0.5462, 0.4538], grad_fn=<DivBackward0>),\n",
       " tensor([0.3743, 0.6257], grad_fn=<DivBackward0>),\n",
       " tensor([0.5625, 0.4375], grad_fn=<DivBackward0>),\n",
       " tensor([0.5724, 0.4276], grad_fn=<DivBackward0>),\n",
       " tensor([0.4320, 0.5680], grad_fn=<DivBackward0>),\n",
       " tensor([0.3397, 0.6603], grad_fn=<DivBackward0>)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d.importance for d in moe_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062415cc-8928-4846-9fce-6d08083de284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bf87500-1af6-4d86-9aa1-988b96387c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(4096, 512)\n",
       "    (drop): Dropout(p=0.2, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-7): 8 x Block(\n",
       "        (ln_1): RMSNorm((512,), eps=None, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=512, out_features=1536, bias=False)\n",
       "          (c_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ln_2): RMSNorm((512,), eps=None, elementwise_affine=True)\n",
       "        (moe): MOE(\n",
       "          (router): TopKRouter(\n",
       "            (gate): Linear(in_features=512, out_features=2, bias=False)\n",
       "            (noisy_gate): Linear(in_features=512, out_features=2, bias=False)\n",
       "          )\n",
       "          (experts): ModuleList(\n",
       "            (0-1): 2 x ExpertNN(\n",
       "              (fc1): Linear(in_features=512, out_features=1365, bias=True)\n",
       "              (fc2): Linear(in_features=1365, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): RMSNorm((512,), eps=None, elementwise_affine=True)\n",
       "    (wpe): Embedding(512, 512)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=4096, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_model.transformer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
